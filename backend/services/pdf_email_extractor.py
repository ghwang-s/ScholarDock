#!/usr/bin/env python3
"""
PDFé‚®ç®±æå–å™¨
ä»è®ºæ–‡PDFçš„ç¬¬ä¸€é¡µæå–ä½œè€…é‚®ç®±
"""
import re
import requests
import tempfile
import os
from typing import List, Optional, Set
from urllib.parse import urlparse
import aiohttp
import asyncio


class PDFEmailExtractor:
    """PDFé‚®ç®±æå–å™¨"""
    
    def __init__(self, proxy: Optional[str] = None):
        """
        åˆå§‹åŒ–PDFé‚®ç®±æå–å™¨
        
        Args:
            proxy: ä»£ç†è®¾ç½®ï¼Œä¾‹å¦‚ "http://127.0.0.1:7890"
        """
        self.proxy = proxy
        self.session = None
        
        # æ£€æŸ¥PDFå¤„ç†åº“
        self.pdf_libraries = self._check_pdf_libraries()
        
    def _check_pdf_libraries(self) -> dict:
        """æ£€æŸ¥å¯ç”¨çš„PDFå¤„ç†åº“"""
        libraries = {}
        
        try:
            import PyPDF2
            libraries['PyPDF2'] = True
        except ImportError:
            libraries['PyPDF2'] = False
            
        try:
            import pdfplumber
            libraries['pdfplumber'] = True
        except ImportError:
            libraries['pdfplumber'] = False
            
        try:
            import fitz  # PyMuPDF
            libraries['PyMuPDF'] = True
        except ImportError:
            libraries['PyMuPDF'] = False
            
        return libraries
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        connector = aiohttp.TCPConnector()
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=aiohttp.ClientTimeout(total=60)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def extract_emails_from_pdf_url(self, pdf_url: str) -> List[str]:
        """
        ä»PDF URLæå–é‚®ç®±
        
        Args:
            pdf_url: PDFæ–‡ä»¶çš„URL
            
        Returns:
            æå–åˆ°çš„é‚®ç®±åˆ—è¡¨
        """
        try:
            print(f"ğŸ” å¼€å§‹ä»PDFæå–é‚®ç®±: {pdf_url}")
            
            # ä¸‹è½½PDFæ–‡ä»¶
            pdf_content = await self._download_pdf(pdf_url)
            if not pdf_content:
                print(f"âŒ æ— æ³•ä¸‹è½½PDFæ–‡ä»¶")
                return []
            
            # æå–ç¬¬ä¸€é¡µæ–‡æœ¬
            first_page_text = self._extract_first_page_text(pdf_content)
            if not first_page_text:
                print(f"âŒ æ— æ³•æå–PDFç¬¬ä¸€é¡µæ–‡æœ¬")
                return []
            
            # ä»æ–‡æœ¬ä¸­æå–é‚®ç®±
            emails = self._extract_emails_from_text(first_page_text)
            
            print(f"ğŸ‰ ä»PDFç¬¬ä¸€é¡µæå–åˆ° {len(emails)} ä¸ªé‚®ç®±")
            return emails
            
        except Exception as e:
            print(f"âŒ PDFé‚®ç®±æå–å¤±è´¥: {e}")
            return []
    
    async def _download_pdf(self, pdf_url: str) -> Optional[bytes]:
        """ä¸‹è½½PDFæ–‡ä»¶"""
        try:
            print(f"ğŸ“¥ ä¸‹è½½PDFæ–‡ä»¶: {pdf_url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            async with self.session.get(
                pdf_url, 
                headers=headers,
                proxy=self.proxy,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    content = await response.read()
                    print(f"âœ… PDFä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(content)} bytes")
                    return content
                else:
                    print(f"âŒ PDFä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    return None
                    
        except Exception as e:
            print(f"âŒ ä¸‹è½½PDFæ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_first_page_text(self, pdf_content: bytes) -> Optional[str]:
        """æå–PDFç¬¬ä¸€é¡µæ–‡æœ¬"""
        
        # å°è¯•ä½¿ç”¨pdfplumberï¼ˆæ¨èï¼‰
        if self.pdf_libraries.get('pdfplumber'):
            try:
                text = self._extract_with_pdfplumber(pdf_content)
                if text:
                    print(f"âœ… ä½¿ç”¨pdfplumberæå–æ–‡æœ¬æˆåŠŸ")
                    print("="*20 + " PDF PLUMBER RAW TEXT " + "="*20)
                    print(text)
                    print("="*50)
                    return text
            except Exception as e:
                print(f"âš ï¸ pdfplumberæå–å¤±è´¥: {e}")
        
        # å°è¯•ä½¿ç”¨PyMuPDF
        if self.pdf_libraries.get('PyMuPDF'):
            try:
                text = self._extract_with_pymupdf(pdf_content)
                if text:
                    print(f"âœ… ä½¿ç”¨PyMuPDFæå–æ–‡æœ¬æˆåŠŸ")
                    print("="*20 + " PYMUPDF RAW TEXT " + "="*20)
                    print(text)
                    print("="*50)
                    return text
            except Exception as e:
                print(f"âš ï¸ PyMuPDFæå–å¤±è´¥: {e}")
        
        # å°è¯•ä½¿ç”¨PyPDF2
        if self.pdf_libraries.get('PyPDF2'):
            try:
                text = self._extract_with_pypdf2(pdf_content)
                if text:
                    print(f"âœ… ä½¿ç”¨PyPDF2æå–æ–‡æœ¬æˆåŠŸ")
                    print("="*20 + " PYPDF2 RAW TEXT " + "="*20)
                    print(text)
                    print("="*50)
                    return text
            except Exception as e:
                print(f"âš ï¸ PyPDF2æå–å¤±è´¥: {e}")
        
        print(f"âŒ æ‰€æœ‰PDFåº“éƒ½æ— æ³•æå–æ–‡æœ¬")
        return None
    
    def _extract_with_pdfplumber(self, pdf_content: bytes) -> Optional[str]:
        """ä½¿ç”¨pdfplumberä»å†…å­˜ä¸­æå–æ–‡æœ¬"""
        import pdfplumber
        import io
        
        try:
            with io.BytesIO(pdf_content) as pdf_stream:
                with pdfplumber.open(pdf_stream) as pdf:
                    if len(pdf.pages) > 0:
                        first_page = pdf.pages[0]
                        # æå–æ–‡æœ¬ï¼ŒåŒæ—¶ä¿ç•™å¸ƒå±€ä¿¡æ¯ï¼Œæœ‰åŠ©äºæŸ¥æ‰¾é‚®ç®±
                        text = first_page.extract_text(x_tolerance=1, y_tolerance=3)
                        return text
        except Exception as e:
            print(f"âš ï¸ pdfplumberä»å†…å­˜æµæå–å¤±è´¥: {e}")
            # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œå°è¯•ä¸´æ—¶æ–‡ä»¶æ–¹æ³•
            return self._extract_with_pdfplumber_fallback(pdf_content)
        return None

    def _extract_with_pdfplumber_fallback(self, pdf_content: bytes) -> Optional[str]:
        """ä½¿ç”¨pdfplumberçš„ä¸´æ—¶æ–‡ä»¶å›é€€æ–¹æ³•"""
        import pdfplumber
        import tempfile
        import os
        
        tmp_file_path = ""
        try:
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
                tmp_file_path = tmp_file.name
                tmp_file.write(pdf_content)
            
            with pdfplumber.open(tmp_file_path) as pdf:
                if len(pdf.pages) > 0:
                    first_page = pdf.pages[0]
                    text = first_page.extract_text(x_tolerance=1, y_tolerance=3)
                    return text
        except Exception as e:
            print(f"âš ï¸ pdfplumberä¸´æ—¶æ–‡ä»¶å›é€€æ–¹æ³•å¤±è´¥: {e}")
            return None
        finally:
            if tmp_file_path and os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
        return None

    def _extract_with_pymupdf(self, pdf_content: bytes) -> Optional[str]:
        """ä½¿ç”¨PyMuPDFä»å†…å­˜ä¸­æå–æ–‡æœ¬"""
        import fitz  # PyMuPDF
        import io

        try:
            # PyMuPDFå¯ä»¥ç›´æ¥ä»bytesæ‰“å¼€
            doc = fitz.open(stream=pdf_content, filetype="pdf")
            if len(doc) > 0:
                first_page = doc[0]
                text = first_page.get_text()
                doc.close()
                return text
        except Exception as e:
            print(f"âš ï¸ PyMuPDFä»å†…å­˜æµæå–å¤±è´¥: {e}")
        
        return None
    
    def _extract_with_pypdf2(self, pdf_content: bytes) -> Optional[str]:
        """ä½¿ç”¨PyPDF2æå–æ–‡æœ¬"""
        import PyPDF2
        import io
        
        pdf_stream = io.BytesIO(pdf_content)
        pdf_reader = PyPDF2.PdfReader(pdf_stream)
        
        if len(pdf_reader.pages) > 0:
            first_page = pdf_reader.pages[0]
            text = first_page.extract_text()
            return text
        
        return None
    
    def _extract_emails_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–é‚®ç®±"""
        emails = set()
        
        print(f"ğŸ” åœ¨PDFæ–‡æœ¬ä¸­æœç´¢é‚®ç®±...")
        print(f"ğŸ“„ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # æ ‡å‡†é‚®ç®±æ ¼å¼
        email_pattern = r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b'
        matches = re.finditer(email_pattern, text, re.IGNORECASE)
        
        for match in matches:
            email = match.group(0).strip()
            if self._is_valid_email(email) and not self._is_spam_email(email):
                emails.add(email)
                print(f"âœ… æ‰¾åˆ°é‚®ç®±: {email}")
        
        # æŸ¥æ‰¾æ··æ·†æ ¼å¼çš„é‚®ç®±
        obfuscated_emails = self._find_obfuscated_emails_in_text(text)
        for email in obfuscated_emails:
            if self._is_valid_email(email) and not self._is_spam_email(email):
                emails.add(email)
                print(f"âœ… æ‰¾åˆ°æ··æ·†é‚®ç®±: {email}")

        # æŸ¥æ‰¾åˆå¹¶æ ¼å¼çš„é‚®ç®±ï¼ˆå¦‚ {user1,user2,user3}@domain.comï¼‰
        merged_emails = self._find_merged_emails_in_text(text)
        for email in merged_emails:
            if self._is_valid_email(email) and not self._is_spam_email(email):
                emails.add(email)
                print(f"âœ… æ‰¾åˆ°åˆå¹¶æ ¼å¼é‚®ç®±: {email}")

        return list(emails)
    
    def _find_obfuscated_emails_in_text(self, text: str) -> List[str]:
        """åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾æ··æ·†æ ¼å¼çš„é‚®ç®±"""
        emails = []
        
        # åŸºæœ¬çš„æ··æ·†æ ¼å¼
        patterns = [
            # AT/DOTæ ¼å¼
            r'\b([a-zA-Z0-9._%+-]+)\s+AT\s+([a-zA-Z0-9.-]+)\s+DOT\s+([a-zA-Z]{2,})\b',
            r'\b([a-zA-Z0-9._%+-]+)\s+at\s+([a-zA-Z0-9.-]+)\s+dot\s+([a-zA-Z]{2,})\b',
            
            # å®Œæ•´åŸŸåæ ¼å¼
            r'\b([a-zA-Z0-9._%+-]+)\s*\[AT\]\s*([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})\b',
            r'\b([a-zA-Z0-9._%+-]+)\s*\(AT\)\s*([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})\b',
            r'\b([a-zA-Z0-9._%+-]+)\s+AT\s+([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})\b',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            
            for match in matches:
                try:
                    if len(match.groups()) == 3:
                        # ä¸‰ç»„æ ¼å¼
                        user_part = match.group(1).strip()
                        domain_part = match.group(2).strip()
                        tld_part = match.group(3).strip()
                        
                        domain_part = domain_part.replace(' dot ', '.').replace(' DOT ', '.')
                        email = f"{user_part}@{domain_part}.{tld_part}"
                        emails.append(email)
                        
                    elif len(match.groups()) == 2:
                        # ä¸¤ç»„æ ¼å¼
                        user_part = match.group(1).strip()
                        domain_part = match.group(2).strip()
                        
                        email = f"{user_part}@{domain_part}"
                        emails.append(email)
                        
                except Exception as e:
                    continue
        
        return emails

    def _find_merged_emails_in_text(self, text: str) -> List[str]:
        """
        åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾åˆå¹¶æ ¼å¼çš„é‚®ç®±

        æ”¯æŒçš„æ ¼å¼ï¼š
        - {user1,user2,user3}@domain.com
        - {shawnxxh,chongyangtao,hishentao}@gmail.com
        - {minglii,tianyi}@umd.edu

        Args:
            text: è¦æœç´¢çš„æ–‡æœ¬

        Returns:
            å±•å¼€åçš„é‚®ç®±åˆ—è¡¨
        """
        emails = []

        try:
            print(f"ğŸ” æœç´¢åˆå¹¶æ ¼å¼é‚®ç®±...")

            # åˆå¹¶æ ¼å¼çš„æ­£åˆ™è¡¨è¾¾å¼
            # åŒ¹é… {user1,user2,user3}@domain.com æ ¼å¼
            merged_pattern = r'\{([a-zA-Z0-9._-]+(?:,[a-zA-Z0-9._-]+)*)\}@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'

            matches = re.finditer(merged_pattern, text, re.IGNORECASE)

            for match in matches:
                try:
                    users_part = match.group(1)  # user1,user2,user3
                    domain_part = match.group(2)  # domain.com

                    # åˆ†å‰²ç”¨æˆ·å
                    usernames = [username.strip() for username in users_part.split(',')]

                    print(f"ğŸ¯ æ‰¾åˆ°åˆå¹¶æ ¼å¼: {{{users_part}}}@{domain_part}")
                    print(f"ğŸ“§ åŒ…å« {len(usernames)} ä¸ªç”¨æˆ·å: {usernames}")

                    # ä¸ºæ¯ä¸ªç”¨æˆ·åç”Ÿæˆé‚®ç®±
                    for username in usernames:
                        if username:  # ç¡®ä¿ç”¨æˆ·åä¸ä¸ºç©º
                            email = f"{username}@{domain_part}"
                            emails.append(email)
                            print(f"   âœ… å±•å¼€é‚®ç®±: {email}")

                except Exception as e:
                    print(f"âš ï¸ å¤„ç†åˆå¹¶æ ¼å¼æ—¶å‡ºé”™: {e}")
                    continue

            # å»é‡
            unique_emails = list(set(emails))

            if unique_emails:
                print(f"ğŸ¯ æ€»å…±å±•å¼€ {len(unique_emails)} ä¸ªåˆå¹¶æ ¼å¼é‚®ç®±")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°åˆå¹¶æ ¼å¼é‚®ç®±")

            return unique_emails

        except Exception as e:
            print(f"âŒ æŸ¥æ‰¾åˆå¹¶æ ¼å¼é‚®ç®±æ—¶å‡ºé”™: {e}")
            return []
    
    def _is_valid_email(self, email: str) -> bool:
        """éªŒè¯é‚®ç®±æ ¼å¼"""
        if not email or '@' not in email:
            return False
        
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(pattern, email))
    
    def _is_spam_email(self, email: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯åƒåœ¾é‚®ç®±"""
        email_lower = email.lower()
        
        spam_domains = [
            'example.com', 'test.com', 'demo.com',
            'localhost', '127.0.0.1', 'noreply'
        ]
        
        spam_prefixes = [
            'admin', 'test', 'demo', 'sample',
            'noreply', 'no-reply', 'donotreply'
        ]
        
        # æ£€æŸ¥åŸŸå
        for domain in spam_domains:
            if domain in email_lower:
                return True
        
        # æ£€æŸ¥å‰ç¼€
        email_prefix = email_lower.split('@')[0] if '@' in email_lower else email_lower
        for prefix in spam_prefixes:
            if email_prefix == prefix:
                return True
        
        return False
